{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc7550-4b4c-453e-820e-78046832c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using semicolon as the delimiter\n",
    "file_path = \"All_data.csv\"\n",
    "df = pd.read_csv(file_path, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Save the dataset with comma as the delimiter\n",
    "df.to_csv(\"All_data_comma.csv\", sep=\",\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820052f-d051-49b3-882e-7b46a3a0659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using comma as the delimiter; read all columns as strings initially\n",
    "file_path = \"All_data_comma.csv\"  \n",
    "df = pd.read_csv(file_path, delimiter=\",\", dtype=str)\n",
    "\n",
    "# Convert 'volgNr' column to numeric format, allowing for missing values\n",
    "df[\"volgNr\"] = pd.to_numeric(df[\"volgNr\"], errors='coerce').astype(\"Int64\")\n",
    "\n",
    "# Define a mapping from original column names to standard month abbreviations\n",
    "periode_kolommen = {\n",
    "    \"strFormuleRealisatiePeriode01\": \"Jan\",\n",
    "    \"strFormuleRealisatiePeriode02\": \"Feb\",\n",
    "    \"strFormuleRealisatiePeriode03\": \"Mar\",\n",
    "    \"strFormuleRealisatiePeriode04\": \"Apr\",\n",
    "    \"strFormuleRealisatiePeriode05\": \"May\",\n",
    "    \"strFormuleRealisatiePeriode06\": \"Jun\",\n",
    "    \"strFormuleRealisatiePeriode07\": \"Jul\",\n",
    "    \"strFormuleRealisatiePeriode08\": \"Aug\",\n",
    "    \"strFormuleRealisatiePeriode09\": \"Sep\",\n",
    "    \"strFormuleRealisatiePeriode10\": \"Oct\",\n",
    "    \"strFormuleRealisatiePeriode11\": \"Nov\",\n",
    "    \"strFormuleRealisatiePeriode12\": \"Dec\"\n",
    "}\n",
    "\n",
    "# Convert all monthly value columns to float (after replacing commas with dots)\n",
    "for col in periode_kolommen.keys():\n",
    "    df[col] = df[col].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Reshape the dataset from wide format to long format (one row per period)\n",
    "df_melted = df.melt(\n",
    "    id_vars=[\"volgNr\", \"Boekjaar\", \"Omschrijving\"],  # keep these columns fixed\n",
    "    value_vars=periode_kolommen.keys(),              # columns to unpivot\n",
    "    var_name=\"Periode\",                              # new column: original column names\n",
    "    value_name=\"Waarde\"                              # new column: values\n",
    ")\n",
    "\n",
    "# Replace long period names with standard month abbreviations\n",
    "df_melted[\"Periode\"] = df_melted[\"Periode\"].map(periode_kolommen)\n",
    "\n",
    "# Create a proper date column combining month and year, formatted as 'YYYY-MM-DD'\n",
    "df_melted[\"Datum\"] = pd.to_datetime(\n",
    "    df_melted[\"Periode\"] + \" \" + df_melted[\"Boekjaar\"].astype(str),\n",
    "    format=\"%b %Y\"\n",
    ").dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Reshape data back into wide format: one row per (farm, date), one column per metric\n",
    "df_final = df_melted.pivot_table(\n",
    "    index=[\"volgNr\", \"Datum\"],\n",
    "    columns=\"Omschrijving\",\n",
    "    values=\"Waarde\",\n",
    "    aggfunc=\"sum\"\n",
    ").reset_index()\n",
    "\n",
    "# Convert values to numeric where possible, keep other types unchanged\n",
    "df_final = df_final.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Save the final transformed dataset to a new CSV file using semicolon as delimiter\n",
    "output_file = \"Transformed_Corrected_All_data.csv\"\n",
    "df_final.to_csv(output_file, index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6de98-ea29-47e3-8375-8ea1202804ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the main transformed dataset\n",
    "file_transformed = \"Transformed_Corrected_All_data.csv\"\n",
    "df_transformed = pd.read_csv(file_transformed, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Load the dataset containing milk cow counts\n",
    "file_melkkoeien = \"melkkoeien.csv\"\n",
    "df_melkkoeien = pd.read_csv(file_melkkoeien, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Standardize column names for consistent merging\n",
    "df_melkkoeien.rename(columns={\"VolgNr\": \"volgnr\"}, inplace=True)\n",
    "df_transformed.rename(columns={\"volgNr\": \"volgnr\"}, inplace=True)\n",
    "\n",
    "# Extract the month number from the indicator name (e.g., \"Aantal_Melkkoeien_03\" → 03)\n",
    "df_melkkoeien[\"Maand\"] = df_melkkoeien[\"KengetalOms\"].str.extract(r'(\\d+)')\n",
    "df_melkkoeien[\"Maand\"] = pd.to_numeric(df_melkkoeien[\"Maand\"], errors=\"coerce\")\n",
    "\n",
    "# Convert cow count values to float (replace comma with dot)\n",
    "df_melkkoeien[\"Aantal\"] = df_melkkoeien[\"Aantal\"].str.replace(\",\", \".\")\n",
    "df_melkkoeien[\"Aantal\"] = pd.to_numeric(df_melkkoeien[\"Aantal\"], errors=\"coerce\")\n",
    "\n",
    "# Extract month and year from the 'Datum' column in the financial dataset\n",
    "df_transformed[\"Maand\"] = pd.to_datetime(df_transformed[\"Datum\"]).dt.month\n",
    "df_transformed[\"Boekjaar\"] = pd.to_datetime(df_transformed[\"Datum\"]).dt.year\n",
    "\n",
    "# Merge the cow count data into the financial data using farm ID, year, and month\n",
    "df_final = df_transformed.merge(df_melkkoeien, on=[\"volgnr\", \"Boekjaar\", \"Maand\"], how=\"left\")\n",
    "\n",
    "# Rename the 'Aantal' column for clarity\n",
    "df_final.rename(columns={\"Aantal\": \"Aantal melkkoeien\"}, inplace=True)\n",
    "\n",
    "# Replace missing cow count values with 0\n",
    "df_final[\"Aantal melkkoeien\"].fillna(0, inplace=True)\n",
    "\n",
    "# Drop columns that are no longer needed\n",
    "df_final.drop(columns=[\"KengetalOms\", \"Kengetal\"], inplace=True)\n",
    "\n",
    "# Save the final merged dataset to a new CSV file\n",
    "output_file = \"Transformed_Corrected_With_Melkkoeien.csv\"\n",
    "df_final.to_csv(output_file, sep=\";\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ad255-a7d6-43c8-b616-d02a76bcdfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset containing financial data and cow counts\n",
    "file_path = \"Transformed_Corrected_With_Melkkoeien.csv\"\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Define the names of the three cash flow components\n",
    "cashflow_columns = [\n",
    "    \"Kasstroom uit bedrijf\",       # Operating cash flow\n",
    "    \"Kasstroom uit financiering\",  # Financing cash flow\n",
    "    \"Kasstroom uit investering\"    # Investing cash flow\n",
    "]\n",
    "\n",
    "# Validate presence of required columns\n",
    "missing_cols = [col for col in cashflow_columns if col not in df.columns]\n",
    "\n",
    "# Calculate the total cash flow by summing the three components\n",
    "df[\"Total Cash Flow\"] = df[cashflow_columns].sum(axis=1)\n",
    "\n",
    "# Drop the original individual cash flow columns to reduce redundancy\n",
    "df.drop(columns=cashflow_columns, inplace=True)\n",
    "\n",
    "# Export the updated dataset to a new CSV file\n",
    "df.to_csv(\"data_cashflow.csv\", sep=\";\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb678ae-d527-4012-a650-07de2a180b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the existing dataset that includes temperature and financial data\n",
    "file_data = \"data_with_temperature.csv\"\n",
    "df_data = pd.read_csv(file_data, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Step 2: Load the monthly precipitation dataset\n",
    "file_precipitation = \"monthly_precipitation.csv\"\n",
    "df_precipitation = pd.read_csv(file_precipitation, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Step 3: Transform the precipitation data into long format\n",
    "df_precipitation = df_precipitation.melt(\n",
    "    id_vars=[\"Jaar\"],                  # Year column remains fixed\n",
    "    var_name=\"Maand\",                  # Original month names become values in a new column\n",
    "    value_name=\"Precipitation (mm)\"   # Precipitation values\n",
    ")\n",
    "\n",
    "# Step 4: Map month abbreviations to numerical month values\n",
    "month_mapping = {\n",
    "    \"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6,\n",
    "    \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12\n",
    "}\n",
    "df_precipitation[\"Maand\"] = df_precipitation[\"Maand\"].map(month_mapping)\n",
    "\n",
    "# Step 5: Merge precipitation data into the main dataset based on year and month\n",
    "df_final = df_data.merge(df_precipitation, on=[\"Jaar\", \"Maand\"], how=\"left\")\n",
    "\n",
    "\n",
    "# Step 6: Export the final enriched dataset to CSV\n",
    "output_file = \"data_with_temperature_precipitation.csv\"\n",
    "df_final.to_csv(output_file, sep=\";\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3987bc-98c9-44aa-8c11-3863b3244ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the combined dataset including financials, livestock, temperature, and precipitation\n",
    "file_path = \"data_with_temperature_precipitation.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Standardize column names: lowercase, replace spaces and periods with underscores\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(\" \", \"_\")\n",
    "      .str.replace(\".\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "# Manually fix any known column name issues\n",
    "df.rename(columns={\"bank,_rekening-courant\": \"bank_rekening_courant\"}, inplace=True)\n",
    "\n",
    "# Print number of missing values per column\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check and report number of duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"\\nNumber of duplicate rows: \", duplicates)\n",
    "\n",
    "# Display summary statistics for all numeric columns\n",
    "print(\"\\nDataset summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e21e29-5252-49ff-9f29-c945757274a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the enriched dataset with financial, climate, and livestock data\n",
    "file_path = \"data_with_temperature_precipitation.csv\"  \n",
    "df = pd.read_csv(file_path, delimiter=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Standardize column names for consistency\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\".\", \"\")\n",
    "\n",
    "# Convert the date column to datetime format\n",
    "df[\"datum\"] = pd.to_datetime(df[\"datum\"], errors=\"coerce\")\n",
    "\n",
    "# Extract time-based features from the date\n",
    "df[\"maand\"] = df[\"datum\"].dt.month        # Month (1–12)\n",
    "df[\"kwartaal\"] = df[\"datum\"].dt.quarter   # Quarter (1–4)\n",
    "df[\"jaar\"] = df[\"datum\"].dt.year          # Year (e.g., 2021)\n",
    "\n",
    "# Define lag periods and the target column\n",
    "lag_features = [1, 3, 6, 12]  \n",
    "target_col = \"totale_kasstroom\"  \n",
    "\n",
    "# Create lag features (previous values of the target)\n",
    "for lag in lag_features:\n",
    "    df[f\"{target_col}_lag{lag}\"] = df[target_col].shift(lag)\n",
    "\n",
    "# Define rolling window sizes (this was missing in your code)\n",
    "rolling_windows = [3, 6, 12]\n",
    "\n",
    "# Create rolling average features over past periods\n",
    "for window in rolling_windows:\n",
    "    df[f\"{target_col}_rolling{window}\"] = df[target_col].rolling(window=window).mean()\n",
    "\n",
    "# Drop rows with NaNs (caused by shifting/rolling at the beginning)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Export the feature-enhanced dataset\n",
    "output_file = \"data_features.csv\"\n",
    "df.to_csv(output_file, sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe12c6-3e8d-49aa-a264-a1419d4357c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"data_features.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "\n",
    "missing_values_summary = df.isnull().sum()\n",
    "missing_values_summary = missing_values_summary[missing_values_summary > 0]\n",
    "\n",
    "Q1 = df['totale_kasstroom'].quantile(0.25)\n",
    "Q3 = df['totale_kasstroom'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_count = ((df['totale_kasstroom'] < lower_bound) | (df['totale_kasstroom'] > upper_bound)).sum()\n",
    "\n",
    "print(f\"Aantal kolommen met missende waarden: {len(missing_values_summary)}\")\n",
    "print(f\"Aantal outliers in totale_kasstroom: {outlier_count}\")\n",
    "\n",
    "zero_threshold = 0.95\n",
    "zero_percentage = (df == 0).sum() / len(df)\n",
    "\n",
    "columns_to_drop = zero_percentage[zero_percentage > zero_threshold].index.tolist()\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Aantal verwijderde kolommen: {len(columns_to_drop)}\")\n",
    "print(f\"Aantal overgebleven kolommen: {df_cleaned.shape[1]}\")\n",
    "\n",
    "df_cleaned.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92a57e-a938-4b37-8519-348af141881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with engineered features\n",
    "file_path = \"data_features.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Ensure the 'datum' column is in datetime format\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "\n",
    "# Identify columns with missing values\n",
    "missing_values_summary = df.isnull().sum()\n",
    "missing_values_summary = missing_values_summary[missing_values_summary > 0]\n",
    "\n",
    "# Detect outliers in the 'totale_kasstroom' column using the IQR method\n",
    "Q1 = df['totale_kasstroom'].quantile(0.25)\n",
    "Q3 = df['totale_kasstroom'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_count = ((df['totale_kasstroom'] < lower_bound) | (df['totale_kasstroom'] > upper_bound)).sum()\n",
    "\n",
    "# Print missing values and outlier summary\n",
    "print(f\"Number of columns with missing values: {len(missing_values_summary)}\")\n",
    "print(f\"Number of outliers in 'totale_kasstroom': {outlier_count}\")\n",
    "\n",
    "# Identify columns with more than 95% zero values\n",
    "zero_threshold = 0.95\n",
    "zero_percentage = (df == 0).sum() / len(df)\n",
    "\n",
    "columns_to_drop = zero_percentage[zero_percentage > zero_threshold].index.tolist()\n",
    "\n",
    "# Drop those low-information columns\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Report the result\n",
    "print(f\"Number of columns removed due to >95% zero values: {len(columns_to_drop)}\")\n",
    "print(f\"Number of remaining columns: {df_cleaned.shape[1]}\")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv(\"cleaned_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d04d7-3a5c-4f15-b2fe-aa507eebb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned dataset\n",
    "file_path = \"cleaned_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'datum' column to datetime and set it as the index\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "df.set_index('datum', inplace=True)\n",
    "\n",
    "# Extract time-based features from the datetime index\n",
    "df['maand'] = df.index.month\n",
    "df['kwartaal'] = df.index.quarter\n",
    "\n",
    "# Perform one-hot encoding on 'month' and 'quarter', dropping the first category to avoid multicollinearity\n",
    "df = pd.get_dummies(df, columns=['maand', 'kwartaal'], drop_first=True)\n",
    "\n",
    "# Export the final feature-engineered dataset\n",
    "df.to_csv(\"feature_engineered_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206a839-7ecc-4b47-b5d0-868514145abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the feature-engineered dataset\n",
    "file_path = \"feature_engineered_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define columns to remove (likely redundant or correlated features)\n",
    "columns_to_remove = [\n",
    "    \"mutatie_liquide_middelen_vlgs_opstelling\",\n",
    "    \"mutatie_liq_middelen_vlgs_administratie\",\n",
    "    \"liquide_middelen\",\n",
    "    \"bank,_rekening-courant\"\n",
    "]\n",
    "\n",
    "# Remove specified columns; ignore errors if any column is missing\n",
    "df_cleaned = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "df_cleaned.to_csv(\"cleaned_feature_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f0990-8795-47f1-b19e-0a50f8d180ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the feature-engineered dataset\n",
    "df = pd.read_csv(\"feature_engineered_data.csv\")\n",
    "\n",
    "# Define the target variable\n",
    "target_column = \"totale_kasstroom\"\n",
    "\n",
    "# Select only numeric columns for correlation analysis\n",
    "numeric_df = df.select_dtypes(include=[\"number\"]).copy()\n",
    "\n",
    "# Ensure rows with missing target values are excluded\n",
    "numeric_df = numeric_df[numeric_df[target_column].notna()]\n",
    "\n",
    "# Compute the absolute correlation matrix\n",
    "corr_matrix = numeric_df.corr().abs()\n",
    "\n",
    "# Extract correlation values with the target (excluding the target itself)\n",
    "target_corr = corr_matrix[target_column].drop(target_column)\n",
    "\n",
    "# Define a correlation threshold for multicollinearity\n",
    "threshold = 0.9\n",
    "to_remove = set()\n",
    "\n",
    "# Iterate over upper triangle of the correlation matrix\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        col1 = corr_matrix.columns[i]\n",
    "        col2 = corr_matrix.columns[j]\n",
    "\n",
    "        # Skip if either column is the target\n",
    "        if col1 == target_column or col2 == target_column:\n",
    "            continue\n",
    "\n",
    "        # If correlation between two features is too high, remove the less informative one\n",
    "        if corr_matrix.loc[col1, col2] > threshold:\n",
    "            corr1 = abs(corr_matrix.loc[col1, target_column])\n",
    "            corr2 = abs(corr_matrix.loc[col2, target_column])\n",
    "\n",
    "            if corr1 >= corr2:\n",
    "                to_remove.add(col2)\n",
    "            else:\n",
    "                to_remove.add(col1)\n",
    "\n",
    "# Drop highly collinear features from the original dataframe\n",
    "df_cleaned = df.drop(columns=to_remove)\n",
    "\n",
    "# Export the final dataset with reduced multicollinearity\n",
    "df_cleaned.to_csv(\"data_no_multicorr.csv\", index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Number of removed features due to high correlation: {len(to_remove)}\")\n",
    "print(f\"Number of remaining features: {df_cleaned.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470db5c8-8b84-48e9-ab56-1be51cba3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the dataset without multicollinearity issues\n",
    "df = pd.read_csv(\"data_no_multicorr.csv\")\n",
    "\n",
    "# 2. Convert the 'datum' column to datetime and sort by farmer and time\n",
    "df[\"datum\"] = pd.to_datetime(df[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "\n",
    "# 3. Function to add lagged and rolling features for each individual farm\n",
    "def add_lagged_features(group):\n",
    "    group = group.copy()\n",
    "    group = group.sort_values(\"datum\")\n",
    "\n",
    "    # Lagged features: previous values\n",
    "    group[\"kasstroom_lag1\"] = group[\"totale_kasstroom\"].shift(1)\n",
    "    group[\"kasstroom_lag3\"] = group[\"totale_kasstroom\"].shift(3)\n",
    "\n",
    "    # Rolling averages (with shift to avoid data leakage)\n",
    "    group[\"kasstroom_rolling3\"] = group[\"totale_kasstroom\"].shift(1).rolling(3).mean()\n",
    "    group[\"kasstroom_rolling6\"] = group[\"totale_kasstroom\"].shift(1).rolling(6).mean()\n",
    "\n",
    "    return group\n",
    "\n",
    "# 4. Apply the feature engineering per individual farmer (volgnr)\n",
    "df_with_lags = df.groupby(\"volgnr\").apply(add_lagged_features).reset_index(drop=True)\n",
    "\n",
    "# 5. Save the enriched dataset\n",
    "df_with_lags.to_csv(\"data_met_lagged_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d8cb3-75e2-44c7-85f3-ab3aaa3afb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with lagged features\n",
    "df = pd.read_csv(\"data_met_lagged_features.csv\")\n",
    "\n",
    "# Ensure the date column is parsed correctly\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "\n",
    "# Create a 'year-month' column for monthly grouping\n",
    "df['jaar_maand'] = df['datum'].dt.to_period('M')\n",
    "\n",
    "# Define realistic price boundaries (€/kg)\n",
    "min_prijs = 0       # No negative prices allowed\n",
    "max_prijs = 5       # Maximum realistic price threshold\n",
    "\n",
    "# Identify outliers for milk and feed price\n",
    "melkprijs_outliers = (df['melkprijs_per_kg'] < min_prijs) | (df['melkprijs_per_kg'] > max_prijs)\n",
    "voerprijs_outliers = (df['voerprijs'] < min_prijs) | (df['voerprijs'] > max_prijs)\n",
    "\n",
    "# Calculate monthly averages using only valid values\n",
    "melkprijs_gemiddelden = df.loc[~melkprijs_outliers].groupby('jaar_maand')['melkprijs_per_kg'].mean()\n",
    "voerprijs_gemiddelden = df.loc[~voerprijs_outliers].groupby('jaar_maand')['voerprijs'].mean()\n",
    "\n",
    "# Replace outliers with the monthly average for that month\n",
    "df.loc[melkprijs_outliers, 'melkprijs_per_kg'] = df.loc[melkprijs_outliers, 'jaar_maand'].map(melkprijs_gemiddelden)\n",
    "df.loc[voerprijs_outliers, 'voerprijs'] = df.loc[voerprijs_outliers, 'jaar_maand'].map(voerprijs_gemiddelden)\n",
    "\n",
    "# Remove the temporary grouping column\n",
    "df.drop(columns='jaar_maand', inplace=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(\"data_corrected_melk_voerprijzen.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be7658-8fe6-4ee7-b306-1c5243cbee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Step 1: Load the cleaned dataset with milk and feed prices\n",
    "df = pd.read_csv(\"data_corrected_melk_voerprijzen.csv\", parse_dates=[\"datum\"])\n",
    "df['datum'] = pd.to_datetime(df['datum'])  # Ensure date is properly parsed\n",
    "\n",
    "# Step 2: Aggregate farm-level business characteristics\n",
    "df_agg = df.groupby('volgnr').agg({\n",
    "    'melkprijs_per_kg': 'mean',         # Average milk price\n",
    "    'voerprijs': 'mean',                # Average feed price\n",
    "    'aankopen_rundvee': 'sum',          # Total cattle purchases\n",
    "    'aanwas_rundvee': 'sum',            # Total cattle growth\n",
    "    'totale_kasstroom': ['mean', 'std'] # Mean and variability of cash flow\n",
    "}).dropna()\n",
    "\n",
    "# Flatten multi-level column names\n",
    "df_agg.columns = ['_'.join(col) for col in df_agg.columns]\n",
    "\n",
    "# Step 3: Normalize features and apply KMeans clustering\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_agg)\n",
    "\n",
    "kmeans_bedrijf = KMeans(n_clusters=3, random_state=42)\n",
    "df_agg['bedrijf_cluster'] = kmeans_bedrijf.fit_predict(X_scaled)\n",
    "\n",
    "# Step 4: Merge cluster labels back into the original dataset\n",
    "df = df.merge(df_agg[['bedrijf_cluster']], left_on='volgnr', right_index=True, how='left')\n",
    "\n",
    "# Step 5: Save the dataset with cluster labels\n",
    "df.to_csv(\"data_with_clusters.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861e760-66de-406a-ab71-8ec190fa3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"data_with_clusters.csv\")\n",
    "\n",
    "# Ensure date column is parsed\n",
    "df['datum'] = pd.to_datetime(df['datum'], errors='coerce')\n",
    "\n",
    "# Identify invalid entries (zero cows)\n",
    "invalid_mask = df['aantal_melkkoeien'] == 0\n",
    "\n",
    "# Step 1: Compute the average number of cows per farm (excluding zeros)\n",
    "bedrijfsgemiddelde = df.loc[~invalid_mask].groupby('volgnr')['aantal_melkkoeien'].mean()\n",
    "\n",
    "# Step 2: Create new column to track imputations\n",
    "df['koeien_geimputeerd'] = False\n",
    "\n",
    "# Step 3: Impute zero values with the farm average\n",
    "impute_mask = invalid_mask & df['volgnr'].isin(bedrijfsgemiddelde.index)\n",
    "df.loc[impute_mask, 'aantal_melkkoeien'] = df.loc[impute_mask, 'volgnr'].map(bedrijfsgemiddelde)\n",
    "df.loc[impute_mask, 'koeien_geimputeerd'] = True\n",
    "\n",
    "# Step 4: Impute remaining (NaNs) with global fallback mean of farm averages\n",
    "df['aantal_melkkoeien'] = df['aantal_melkkoeien'].fillna(bedrijfsgemiddelde.mean())\n",
    "df.loc[df['aantal_melkkoeien'] == bedrijfsgemiddelde.mean(), 'koeien_geimputeerd'] = True\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(\"data_with_clusters.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b604b-279f-4434-8c13-fdaac3f0613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load and sort the dataset\n",
    "df = pd.read_csv(\"data_with_clusters.csv\")\n",
    "df[\"datum\"] = pd.to_datetime(df[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Define variables and their Granger-relevant lags\n",
    "granger_lags = {\n",
    "    \"totale_kasstroom\": [1, 3],\n",
    "    \"melkprijs_per_kg\": [1, 3, 6],\n",
    "    \"totaal_opbrengsten\": [1, 3, 6],\n",
    "    \"krachtvoerkosten\": [1, 3, 6],\n",
    "    \"voerkosten\": [4, 5, 6],\n",
    "    \"gemiddelde_temperatuur\": [5, 6],\n",
    "}\n",
    "\n",
    "# Step 3: Function to apply lag features without leakage (per farm)\n",
    "def add_granger_lags(group):\n",
    "    group = group.sort_values(\"datum\").copy()\n",
    "    \n",
    "    for var, lags in granger_lags.items():\n",
    "        if var in group.columns:\n",
    "            for lag in lags:\n",
    "                colname = f\"{var}_lag_{lag}\"\n",
    "                group[colname] = group[var].shift(lag)\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Step 4: Apply the lag function per farmer ('volgnr')\n",
    "df_lagged = df.groupby(\"volgnr\").apply(add_granger_lags).reset_index(drop=True)\n",
    "\n",
    "df_lagged.to_csv(\"data_met_granger_lags.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca793a-82a6-47f1-9bb4-6b262355415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with winsorized financial features\n",
    "df = pd.read_csv(\"data_met_granger_lags.csv\")\n",
    "\n",
    "# Define columns where negative values are invalid and should be corrected\n",
    "cols_to_fix = [\"voerkosten\", \"krachtvoerkosten\", \"totaal_opbrengsten\"]\n",
    "\n",
    "# Correct negative values by taking the absolute value\n",
    "for col in cols_to_fix:\n",
    "    df[col] = df[col].abs()\n",
    "\n",
    "df.to_csv(\"data_final.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
