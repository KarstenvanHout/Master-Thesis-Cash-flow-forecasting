{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d85cd-da64-441f-a473-94c8ebad2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 1. Load and sort data\n",
    "df = pd.read_csv(\"data_final.csv\", parse_dates=[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "\n",
    "# 2. Time-based features\n",
    "df[\"jaar\"] = df[\"datum\"].dt.year\n",
    "df[\"maand\"] = df[\"datum\"].dt.month\n",
    "\n",
    "# 3. Define target: next month's cash flow\n",
    "df[\"target\"] = df.groupby(\"volgnr\")[\"totale_kasstroom\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# Apply winsorization (same logic as XGBoost model)\n",
    "df[\"target\"] = pd.Series(winsorize(df[\"target\"], limits=[0.01, 0.01]), index=df.index)\n",
    "\n",
    "# 4. Add lagged and derived features\n",
    "df[\"eindsaldo_liquide_middelen_lag_1\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(1)\n",
    "df[\"mutaties_vorderingen_en_schulden_lag_1\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(1)\n",
    "df[\"eindsaldo_liquide_middelen_lag_6\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(6)\n",
    "df[\"mutaties_lag_6\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(6)\n",
    "df[\"ratio_schulden_opbrengst\"] = df[\"mutaties_vorderingen_en_schulden\"] / (df[\"totaal_opbrengsten_lag_1\"] + 1e-6)\n",
    "df[\"kasratio\"] = df[\"kas\"] / (df[\"totale_kasstroom_lag_1\"] + 1e-6)\n",
    "df[\"melkprijs_diff_6\"] = df[\"melkprijs_per_kg\"] - df[\"melkprijs_per_kg\"].shift(6)\n",
    "\n",
    "# 4b. Fill NaNs in lagged/diff columns per farm\n",
    "lagged_cols = [col for col in df.columns if any(p in col for p in [\"_lag_\", \"_diff_\", \"ratio_\", \"kasratio\"])]\n",
    "df[lagged_cols] = df.groupby(\"volgnr\")[lagged_cols].transform(lambda x: x.bfill().ffill())\n",
    "\n",
    "# 5. Train/validation/test split by farm\n",
    "farms = df[\"volgnr\"].unique()\n",
    "trainval_farms, test_farms = train_test_split(farms, test_size=0.2, random_state=42)\n",
    "train_farms, val_farms = train_test_split(trainval_farms, test_size=0.2, random_state=42)\n",
    "\n",
    "df[\"is_train\"] = df[\"volgnr\"].isin(train_farms) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_val\"] = df[\"volgnr\"].isin(val_farms) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_test\"] = df[\"volgnr\"].isin(test_farms) & (df[\"jaar\"] == 2024)\n",
    "\n",
    "# 6. Top 50 most important features according to SHAP values from XGBoost model\n",
    "NUM_FEATURES_TO_USE = 50\n",
    "all_features = [f for f in [\n",
    "    'eindsaldo_liquide_middelen', 'mutaties_vorderingen_en_schulden', 'overige_vorderingen', 'melkprijs_per_kg',\n",
    "    'crediteuren', 'melkprijs_per_kg_lag_6', 'leningen.1', 'mutatie_crediteuren',\n",
    "    'resultaat_vóór_bijzondere_resultaten', 'energiekosten', 'neerslag_(mm)', 'totale_kasstroom_lag_1',\n",
    "    'voorschot_melkgeld', 'melkprijs_per_kg_lag_1', 'maand', 'totaal_opbrengsten_lag_3',\n",
    "    'volgnr', 'debiteuren', 'grasland', 'accountantskosten',\n",
    "    'koesaldo_per_kg_fosfaat', 'melkprijs_per_kg_lag_3', 'daadwerkelijke_aflossingen_in_het_jaar',\n",
    "    'ruwvoeraankopen.1', 'gewasbeschermingsmiddelen', 'overige_mutaties_operationele_activiteiten',\n",
    "    'krachtvoerkosten_lag_6', 'totale_kosten_excl_afschrijvingen', 'totaal_opbrengsten_lag_6',\n",
    "    'overige_banken', 'schoonmaakkosten_gebouwen', 'saldo_omzetbelasting',\n",
    "    'opfokkosten_en_weidegeld_per_100_kg_melk', 'melkkoeien_(€)', 'krachtvoerkosten', 'gebouwen',\n",
    "    'overige_bedrijfsopbrengsten', 'eiwitgehalte', 'financiële_baten_en_lasten',\n",
    "    'afschrijving_productierechten', 'totaal_opbrengsten_lag_1', 'resultaat_vóór_belastingen',\n",
    "    'totale_uitgaven', 'marge', 'aantal_melkkoeien_per_ha', 'voerkosten',\n",
    "    'gemiddelde_temperatuur', 'boekjaar', 'mutatie_debiteuren', 'totaal_opbrengsten',\n",
    "    'afschrijving_auto(s)', 'opbrengst_nuka', 'personeelskosten_%_van_de_opbrengsten',\n",
    "    '%_insteek_van_de_melkkoeien', 'bijzondere_resultaten', 'kas', 'gemiddelde_temperatuur_lag_6',\n",
    "    'investering_grond_en_gebouwen', 'ureumgehalte', 'waarvan_loonwerk_per_ha',\n",
    "    'onttrekkingen,_prive_xb9010', 'percentage_jongvee', 'ruwvoerkosten.1',\n",
    "    'advieskosten', 'pensioenlasten', 'bedrijfskosten', 'gas,_water_en_electra',\n",
    "    'overige_kosten_inventaris_en_machines', \"eindsaldo_liquide_middelen_lag_1\",\n",
    "    \"mutaties_vorderingen_en_schulden_lag_1\", \"eindsaldo_liquide_middelen_lag_6\",\n",
    "    \"mutaties_lag_6\", \"ratio_schulden_opbrengst\", \"kasratio\", \"melkprijs_diff_6\"\n",
    "] if f in df.columns]\n",
    "features = all_features[:NUM_FEATURES_TO_USE]\n",
    "\n",
    "# 7. Build sequences\n",
    "sequence_length = 12\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, sequence_datums = [], [], [], [], [], [], []\n",
    "\n",
    "def build_sequences(farm_df, flag_col):\n",
    "    X_seq, y_seq, datums = [], [], []\n",
    "    for i in range(len(farm_df) - sequence_length):\n",
    "        input_window = farm_df.iloc[i:i + sequence_length]\n",
    "        target_row = farm_df.iloc[i + sequence_length]\n",
    "        if not input_window[flag_col].all() and not target_row[flag_col]:\n",
    "            continue\n",
    "        X_seq.append(input_window[features].values)\n",
    "        y_seq.append(target_row[\"target\"])\n",
    "        datums.append(target_row[\"datum\"])\n",
    "    return X_seq, y_seq, datums\n",
    "\n",
    "for _, farm_df in df.groupby(\"volgnr\"):\n",
    "    farm_df = farm_df.sort_values(\"datum\")\n",
    "    x_tr, y_tr, _ = build_sequences(farm_df, \"is_train\")\n",
    "    x_va, y_va, _ = build_sequences(farm_df, \"is_val\")\n",
    "    x_te, y_te, dts = build_sequences(farm_df, \"is_test\")\n",
    "    X_train.extend(x_tr)\n",
    "    y_train.extend(y_tr)\n",
    "    X_val.extend(x_va)\n",
    "    y_val.extend(y_va)\n",
    "    X_test.extend(x_te)\n",
    "    y_test.extend(y_te)\n",
    "    sequence_datums.extend(dts)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 8. Normalize features and targets\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[2])).reshape(X_train.shape)\n",
    "X_val_scaled = feature_scaler.transform(X_val.reshape(-1, X_val.shape[2])).reshape(X_val.shape)\n",
    "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[2])).reshape(X_test.shape)\n",
    "\n",
    "# 9. Final shape check\n",
    "print(\"X_train:\", X_train_scaled.shape)\n",
    "print(\"X_val:  \", X_val_scaled.shape)\n",
    "print(\"X_test: \", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a443d3-b793-46cb-91fc-3db81f0fd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Build a GRU model with parameters chosen by Optuna\n",
    "def create_gru_model(trial, input_shape):\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 256)  # number of units per GRU layer\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)  # dropout rate between layers\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)  # learning rate\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)  # number of GRU layers\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.GRU(hidden_size, return_sequences=(num_layers > 1), input_shape=input_shape))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "\n",
    "    for i in range(1, num_layers):  # add additional GRU layers if applicable\n",
    "        return_seq = i < num_layers - 1\n",
    "        model.add(layers.GRU(hidden_size, return_sequences=return_seq))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "\n",
    "    model.add(layers.Dense(1))  # output layer for regression\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=\"mean_squared_error\")  # optimizer and loss function\n",
    "    return model\n",
    "\n",
    "# Objective function for Optuna: minimize RMSE on the validation set\n",
    "def objective(trial):\n",
    "    model = create_gru_model(trial, X_train_scaled.shape[1:])  # build model\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # prevent overfitting\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, y_train_scaled,\n",
    "        validation_data=(X_val_scaled, y_val_scaled),\n",
    "        epochs=15,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0  # suppress training output\n",
    "    )\n",
    "\n",
    "    y_val_pred = model.predict(X_val_scaled)  # predictions on validation set\n",
    "    y_val_pred_unscaled = target_scaler.inverse_transform(y_val_pred)  # inverse transform\n",
    "    y_val_unscaled = target_scaler.inverse_transform(y_val_scaled)  # true values\n",
    "\n",
    "    rmse = mean_squared_error(y_val_unscaled, y_val_pred_unscaled, squared=False)  # RMSE\n",
    "    return rmse\n",
    "\n",
    "# Launch Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)  # run 30 trials\n",
    "\n",
    "# Print best hyperparameters and corresponding RMSE\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value (RMSE):\", study.best_value)\n",
    "print(\"  Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2271f-3b6a-44ed-892f-1d7e6420a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from tensorflow.keras.losses import Huber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set hyperparameters\n",
    "hidden_size = 130\n",
    "num_layers = 1\n",
    "dropout = 0.49695170305447367\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0006011904275630357\n",
    "\n",
    "# Define GRU model\n",
    "model = models.Sequential()\n",
    "model.add(layers.GRU(hidden_size, return_sequences=(num_layers > 1), input_shape=X_train_scaled.shape[1:]))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "for _ in range(num_layers - 1):\n",
    "    model.add(layers.GRU(hidden_size, return_sequences=(_ < num_layers - 2)))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Dense(1))  # Output layer for regression\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=Huber(delta=1.0))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train model (without early stopping)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict on all sets (scaled)\n",
    "y_train_pred_scaled = model.predict(X_train_scaled)\n",
    "y_val_pred_scaled = model.predict(X_val_scaled)\n",
    "y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_train_pred = target_scaler.inverse_transform(y_train_pred_scaled)\n",
    "y_val_pred = target_scaler.inverse_transform(y_val_pred_scaled)\n",
    "y_test_pred = target_scaler.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "# Diagnostics output\n",
    "print(\"\\nPost inverse_transform check:\")\n",
    "print(\"Unscaled predictions (test):\", y_test_pred[:5].flatten())\n",
    "print(\"Actual y_test:\", y_test[:5])\n",
    "\n",
    "print(\"\\nStandard deviation check:\")\n",
    "print(\"std(y_test):\", np.std(y_test))\n",
    "print(\"std(y_test_pred):\", np.std(y_test_pred))\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(true, pred, label):\n",
    "    rmse = mean_squared_error(true, pred, squared=False)\n",
    "    r2 = r2_score(true, pred)\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    print(f\"\\n{label} Results:\")\n",
    "    print(f\"RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    print(f\"MAE: €{mae:,.2f}\")\n",
    "    return rmse, r2, mae\n",
    "\n",
    "# Run evaluation\n",
    "evaluate(y_train, y_train_pred, \"Train\")\n",
    "evaluate(y_val, y_val_pred, \"Validation\")\n",
    "evaluate(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Monthly average plot for test predictions\n",
    "df_preds = pd.DataFrame({\n",
    "    \"date\": sequence_datums[-len(y_test):],\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_test_pred.flatten()\n",
    "})\n",
    "df_preds[\"month\"] = pd.to_datetime(df_preds[\"date\"]).dt.month\n",
    "monthly_avg = df_preds.groupby(\"month\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", marker=\"o\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted\", marker=\"o\", linestyle=\"--\")\n",
    "plt.title(\"GRU Forecast – 2024 (Test Farms)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe8045-d992-4003-91ea-65ab160314ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all training target dates again\n",
    "train_sequence_datums = []\n",
    "for boer_id, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if input_window[\"is_train\"].all():\n",
    "            train_sequence_datums.append(target_row[\"datum\"])\n",
    "\n",
    "# Construct DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    \"datum\": pd.to_datetime(train_sequence_datums + sequence_datums),\n",
    "    \"y_true\": np.concatenate([y_train.flatten(), y_test.flatten()]),\n",
    "    \"y_pred\": np.concatenate([np.full_like(y_train.flatten(), np.nan), y_test_pred.flatten()])\n",
    "})\n",
    "\n",
    "# Set date index for resampling\n",
    "df_plot = df_plot.sort_values(\"datum\").set_index(\"datum\")\n",
    "\n",
    "# Aggregate monthly averages\n",
    "monthly_avg = df_plot.resample(\"M\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", color=\"blue\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted (2024)\", color=\"orangered\", linestyle=\"--\")\n",
    "plt.title(\"GRU Forecast With Exogenous Variables – Monthly Average Cash Flow (2020–2024)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9c096-8395-41a7-8417-ad353a3595c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "# Permutation-based feature importance for sequence models\n",
    "def permutation_feature_importance(model, X, y_true, scaler, baseline_preds, feature_names, n_repeats=5):\n",
    "    baseline_rmse = mean_squared_error(y_true, baseline_preds, squared=False)\n",
    "    importances = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(X.shape[2]), desc=\"Calculating feature importance\"):\n",
    "        rmse_diffs = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = copy.deepcopy(X)\n",
    "            for t in range(X.shape[1]):\n",
    "                np.random.shuffle(X_permuted[:, t, i])  # Permute feature across timesteps\n",
    "            y_pred_scaled = model.predict(X_permuted)\n",
    "            y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "            rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "            rmse_diffs.append(rmse - baseline_rmse)\n",
    "        importances.append(np.mean(rmse_diffs))\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": feature_names,\n",
    "        \"Importance (RMSE increase)\": importances\n",
    "    }).sort_values(by=\"Importance (RMSE increase)\", ascending=False)\n",
    "\n",
    "    return importance_df\n",
    "\n",
    "# Baseline predictions from the model\n",
    "baseline_preds = y_test_pred  \n",
    "\n",
    "# Feature names used in the model\n",
    "feature_names = feature_cols  \n",
    "\n",
    "# Compute permutation importances\n",
    "importance_df = permutation_feature_importance(\n",
    "    model=model,\n",
    "    X=X_test_scaled,\n",
    "    y_true=y_test,\n",
    "    scaler=target_scaler,\n",
    "    baseline_preds=baseline_preds,\n",
    "    feature_names=feature_names,\n",
    "    n_repeats=5  \n",
    ")\n",
    "\n",
    "# Plot top 10 features\n",
    "top10 = importance_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(top10[\"Feature\"][::-1], top10[\"Importance (RMSE increase)\"][::-1])\n",
    "plt.xlabel(\"Increase in RMSE when permuted\")\n",
    "plt.title(\"Top 10 Feature Importances (GRU – Permutation)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014dc7f-8221-44cf-8ce8-db4a681a313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from Dutch to English feature names\n",
    "translation_dict = {\n",
    "    \"eindsaldo_liquide_middelen\": \"ending_cash_balance\",\n",
    "    \"totaal_opbrengsten\": \"total_revenue\",\n",
    "    \"debiteuren\": \"accounts_receivable\",\n",
    "    \"melkprijs_per_kg_lag_1\": \"milk_price_lag_1\",\n",
    "    \"totaal_opbrengsten_lag_3\": \"total_revenue_lag_3\",\n",
    "    \"totaal_opbrengsten_lag_6\": \"total_revenue_lag_6\",\n",
    "    \"schoonmaakkosten_gebouwen\": \"building_cleaning_costs\",\n",
    "    \"overige_vorderingen\": \"other_receivables\",\n",
    "    \"overige_banken\": \"other_banks\",\n",
    "    \"koesaldo_per_kg_fosfaat\": \"cow_balance_per_kg_phosphate\"\n",
    "}\n",
    "\n",
    "# Replace feature names if they appear in the dictionary\n",
    "importance_df[\"Feature\"] = importance_df[\"Feature\"].map(lambda x: translation_dict.get(x, x))\n",
    "\n",
    "# Plot top 10 features\n",
    "top10 = importance_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(top10[\"Feature\"][::-1], top10[\"Importance (RMSE increase)\"][::-1])\n",
    "plt.xlabel(\"Increase in RMSE when permuted\")\n",
    "plt.title(\"Top 10 Feature Importances (GRU – Permutation)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6735b5-bf00-4814-a8ed-ec210f0242a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 1. Load and sort data\n",
    "df = pd.read_csv(\"data_final.csv\", parse_dates=[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "df[\"jaar\"] = df[\"datum\"].dt.year\n",
    "df[\"maand\"] = df[\"datum\"].dt.month\n",
    "\n",
    "# 2. Create target (1 month ahead)\n",
    "df[\"target\"] = df.groupby(\"volgnr\")[\"totale_kasstroom\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df[\"target\"] = pd.Series(winsorize(df[\"target\"], limits=[0.01, 0.01]), index=df.index)  # Winsorize instead of clipping\n",
    "\n",
    "# 3. Add engineered features\n",
    "df[\"eindsaldo_liquide_middelen_lag_1\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(1)\n",
    "df[\"mutaties_vorderingen_en_schulden_lag_1\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(1)\n",
    "df[\"eindsaldo_liquide_middelen_lag_6\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(6)\n",
    "df[\"mutaties_lag_6\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(6)\n",
    "df[\"ratio_schulden_opbrengst\"] = df[\"mutaties_vorderingen_en_schulden\"] / (df[\"totaal_opbrengsten_lag_1\"] + 1e-6)\n",
    "df[\"kasratio\"] = df[\"kas\"] / (df[\"totale_kasstroom_lag_1\"] + 1e-6)\n",
    "df[\"melkprijs_diff_6\"] = df[\"melkprijs_per_kg\"] - df[\"melkprijs_per_kg\"].shift(6)\n",
    "\n",
    "# 4. Impute lagged/diff/ratio columns within each farm\n",
    "lagged_cols = [col for col in df.columns if any(pat in col for pat in [\"_lag_\", \"_diff_\", \"ratio_\", \"kasratio\"])]\n",
    "df[lagged_cols] = df.groupby(\"volgnr\")[lagged_cols].transform(lambda x: x.bfill().ffill())\n",
    "\n",
    "# 5. Train/val/test split\n",
    "boeren = df[\"volgnr\"].unique()\n",
    "trainval_boeren, test_boeren = train_test_split(boeren, test_size=0.2, random_state=42)\n",
    "train_boeren, val_boeren = train_test_split(trainval_boeren, test_size=0.2, random_state=42)\n",
    "df[\"is_train\"] = df[\"volgnr\"].isin(train_boeren) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_val\"] = df[\"volgnr\"].isin(val_boeren) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_test\"] = df[\"volgnr\"].isin(test_boeren) & (df[\"jaar\"] == 2024)\n",
    "\n",
    "# 6. Select top features\n",
    "NUM_FEATURES_TO_USE = 50\n",
    "top_features = [  # (full list remains unchanged)\n",
    "    'eindsaldo_liquide_middelen', 'mutaties_vorderingen_en_schulden', 'overige_vorderingen', 'melkprijs_per_kg',\n",
    "    'crediteuren', 'melkprijs_per_kg_lag_6', 'leningen.1', 'mutatie_crediteuren',\n",
    "    'resultaat_vóór_bijzondere_resultaten', 'energiekosten', 'neerslag_(mm)', 'totale_kasstroom_lag_1',\n",
    "    'voorschot_melkgeld', 'melkprijs_per_kg_lag_1', 'maand', 'totaal_opbrengsten_lag_3',\n",
    "    'volgnr', 'debiteuren', 'grasland', 'accountantskosten',\n",
    "    'koesaldo_per_kg_fosfaat', 'melkprijs_per_kg_lag_3', 'daadwerkelijke_aflossingen_in_het_jaar',\n",
    "    'ruwvoeraankopen.1', 'gewasbeschermingsmiddelen', 'overige_mutaties_operationele_activiteiten',\n",
    "    'krachtvoerkosten_lag_6', 'totale_kosten_excl_afschrijvingen', 'totaal_opbrengsten_lag_6',\n",
    "    'overige_banken', 'schoonmaakkosten_gebouwen', 'saldo_omzetbelasting',\n",
    "    'opfokkosten_en_weidegeld_per_100_kg_melk', 'melkkoeien_(€)', 'krachtvoerkosten', 'gebouwen',\n",
    "    'overige_bedrijfsopbrengsten', 'eiwitgehalte', 'financiële_baten_en_lasten',\n",
    "    'afschrijving_productierechten', 'totaal_opbrengsten_lag_1', 'resultaat_vóór_belastingen',\n",
    "    'totale_uitgaven', 'marge', 'aantal_melkkoeien_per_ha', 'voerkosten',\n",
    "    'gemiddelde_temperatuur', 'boekjaar', 'mutatie_debiteuren', 'totaal_opbrengsten',\n",
    "    'afschrijving_auto(s)', 'opbrengst_nuka', 'personeelskosten_%_van_de_opbrengsten',\n",
    "    '%_insteek_van_de_melkkoeien', 'bijzondere_resultaten', 'kas', 'gemiddelde_temperatuur_lag_6',\n",
    "    'investering_grond_en_gebouwen', 'ureumgehalte', 'waarvan_loonwerk_per_ha',\n",
    "    'onttrekkingen,_prive_xb9010', 'percentage_jongvee', 'ruwvoerkosten.1',\n",
    "    'advieskosten', 'pensioenlasten', 'bedrijfskosten', 'gas,_water_en_electra',\n",
    "    'overige_kosten_inventaris_en_machines', \"eindsaldo_liquide_middelen_lag_1\",\n",
    "    \"mutaties_vorderingen_en_schulden_lag_1\", \"eindsaldo_liquide_middelen_lag_6\",\n",
    "    \"mutaties_lag_6\", \"ratio_schulden_opbrengst\", \"kasratio\", \"melkprijs_diff_6\"\n",
    "]\n",
    "feature_cols = [col for col in top_features[:NUM_FEATURES_TO_USE] if col in df.columns]\n",
    "\n",
    "# 7. Build sequences\n",
    "sequence_length = 12\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "sequence_datums, sequence_volgnrs = [], []\n",
    "\n",
    "def build_sequences(boer_df, flag_col):\n",
    "    X_seq, y_seq, datums, volgnrs = [], [], [], []\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if not input_window[flag_col].all() and not target_row[flag_col]:\n",
    "            continue\n",
    "        X_seq.append(input_window[feature_cols].values)\n",
    "        y_seq.append(target_row[\"target\"])\n",
    "        datums.append(target_row[\"datum\"])\n",
    "        volgnrs.append(target_row[\"volgnr\"])\n",
    "    return X_seq, y_seq, datums, volgnrs\n",
    "\n",
    "for _, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    x_tr, y_tr, _, _ = build_sequences(boer_df, \"is_train\")\n",
    "    x_va, y_va, _, _ = build_sequences(boer_df, \"is_val\")\n",
    "    x_te, y_te, dts, vols = build_sequences(boer_df, \"is_test\")\n",
    "    X_train.extend(x_tr)\n",
    "    y_train.extend(y_tr)\n",
    "    X_val.extend(x_va)\n",
    "    y_val.extend(y_va)\n",
    "    X_test.extend(x_te)\n",
    "    y_test.extend(y_te)\n",
    "    sequence_datums.extend(dts)\n",
    "    sequence_volgnrs.extend(vols)\n",
    "\n",
    "# 8. Scaling\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[2])).reshape(X_train.shape)\n",
    "X_val_scaled = feature_scaler.transform(X_val.reshape(-1, X_val.shape[2])).reshape(X_val.shape)\n",
    "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[2])).reshape(X_test.shape)\n",
    "\n",
    "# 9. GRU model (zonder early stopping)\n",
    "hidden_size = 130\n",
    "num_layers = 1\n",
    "dropout = 0.49695170305447367\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0006011904275630357\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.GRU(hidden_size, return_sequences=(num_layers > 1), input_shape=X_train_scaled.shape[1:]))\n",
    "model.add(layers.Dropout(dropout))\n",
    "for _ in range(num_layers - 1):\n",
    "    model.add(layers.GRU(hidden_size, return_sequences=(_ < num_layers - 2)))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mean_squared_error\")\n",
    "\n",
    "# 10. Train the model (zonder early stopping)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 11. Make predictions\n",
    "y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "y_test_pred = target_scaler.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "# 12. Cluster evaluation\n",
    "df_test_preds = pd.DataFrame({\n",
    "    \"datum\": sequence_datums,\n",
    "    \"volgnr\": sequence_volgnrs,\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_test_pred.flatten()\n",
    "})\n",
    "df_clusters = df[[\"datum\", \"volgnr\", \"bedrijf_cluster\"]].drop_duplicates()\n",
    "df_test_preds = df_test_preds.merge(df_clusters, on=[\"datum\", \"volgnr\"], how=\"left\")\n",
    "\n",
    "def evaluate(true, pred, label):\n",
    "    rmse = mean_squared_error(true, pred, squared=False)\n",
    "    r2 = r2_score(true, pred)\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    print(f\"\\n{label} Results:\")\n",
    "    print(f\"RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    print(f\"MAE: €{mae:,.2f}\")\n",
    "    return rmse, r2, mae\n",
    "\n",
    "for cluster in df_test_preds[\"bedrijf_cluster\"].dropna().unique():\n",
    "    subset = df_test_preds[df_test_preds[\"bedrijf_cluster\"] == cluster]\n",
    "    evaluate(subset[\"y_true\"], subset[\"y_pred\"], f\"Cluster {cluster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f427a0-c4e5-4c4c-8a75-353ee3521210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Recollect training dates and farm IDs\n",
    "train_sequence_datums = []\n",
    "train_sequence_volgnrs = []\n",
    "for boer_id, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if input_window[\"is_train\"].all():\n",
    "            train_sequence_datums.append(target_row[\"datum\"])\n",
    "            train_sequence_volgnrs.append(target_row[\"volgnr\"])\n",
    "\n",
    "# Build combined DataFrame with train and test predictions\n",
    "df_plot = pd.DataFrame({\n",
    "    \"datum\": pd.to_datetime(train_sequence_datums + sequence_datums),\n",
    "    \"volgnr\": np.concatenate([train_sequence_volgnrs, sequence_volgnrs]),\n",
    "    \"y_true\": np.concatenate([y_train.flatten(), y_test.flatten()]),\n",
    "    \"y_pred\": np.concatenate([np.full_like(y_train.flatten(), np.nan), y_test_pred.flatten()])\n",
    "})\n",
    "\n",
    "# Merge cluster information\n",
    "df_clusters = df[[\"datum\", \"volgnr\", \"bedrijf_cluster\"]].drop_duplicates()\n",
    "df_plot = df_plot.merge(df_clusters, on=[\"datum\", \"volgnr\"], how=\"left\")\n",
    "\n",
    "# Set datetime index\n",
    "df_plot = df_plot.sort_values(\"datum\").set_index(\"datum\")\n",
    "\n",
    "# Create subplot layout for each cluster\n",
    "unique_clusters = sorted(df_plot[\"bedrijf_cluster\"].dropna().unique())\n",
    "n_clusters = len(unique_clusters)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_clusters, figsize=(6 * n_clusters, 5), sharey=True)\n",
    "\n",
    "for i, cluster in enumerate(unique_clusters):\n",
    "    ax = axes[i] if n_clusters > 1 else axes\n",
    "    df_cluster = df_plot[df_plot[\"bedrijf_cluster\"] == cluster]\n",
    "\n",
    "    # Resample monthly averages\n",
    "    monthly_avg = df_cluster.resample(\"M\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "    ax.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual (2020–2024)\", color=\"blue\")\n",
    "    ax.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted (2024)\", color=\"orangered\", linestyle=\"--\")\n",
    "    ax.set_title(f\"Cluster {int(cluster)}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Average Cash Flow (€)\")\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle(\"GRU Forecast – Monthly Average Cash Flow per Cluster (2020–2024)\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309be1ad-6846-466e-a125-d2948ff45e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 1. Load and sort data\n",
    "df = pd.read_csv(\"data_final.csv\", parse_dates=[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "\n",
    "# 2. Create time features\n",
    "df[\"jaar\"] = df[\"datum\"].dt.year\n",
    "df[\"maand\"] = df[\"datum\"].dt.month\n",
    "\n",
    "# 3. Create target (next month cash flow)\n",
    "df[\"target\"] = df.groupby(\"volgnr\")[\"totale_kasstroom\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df[\"target\"] = pd.Series(winsorize(df[\"target\"], limits=[0.01, 0.01]), index=df.index)  # Apply winsorization\n",
    "\n",
    "# 4. Add engineered features\n",
    "df[\"eindsaldo_liquide_middelen_lag_1\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(1)\n",
    "df[\"mutaties_vorderingen_en_schulden_lag_1\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(1)\n",
    "df[\"eindsaldo_liquide_middelen_lag_6\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(6)\n",
    "df[\"mutaties_lag_6\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(6)\n",
    "df[\"ratio_schulden_opbrengst\"] = df[\"mutaties_vorderingen_en_schulden\"] / (df[\"totaal_opbrengsten_lag_1\"] + 1e-6)\n",
    "df[\"kasratio\"] = df[\"kas\"] / (df[\"totale_kasstroom_lag_1\"] + 1e-6)\n",
    "df[\"melkprijs_diff_6\"] = df[\"melkprijs_per_kg\"] - df[\"melkprijs_per_kg\"].shift(6)\n",
    "\n",
    "# 5. Fill engineered features within each farm\n",
    "lagged_cols = [col for col in df.columns if any(pat in col for pat in [\"_lag_\", \"_diff_\", \"ratio_\", \"kasratio\"])]\n",
    "df[lagged_cols] = df.groupby(\"volgnr\")[lagged_cols].transform(lambda x: x.bfill().ffill())\n",
    "\n",
    "# 6. Train/val/test split\n",
    "boeren = df[\"volgnr\"].unique()\n",
    "trainval_boeren, test_boeren = train_test_split(boeren, test_size=0.2, random_state=42)\n",
    "train_boeren, val_boeren = train_test_split(trainval_boeren, test_size=0.2, random_state=42)\n",
    "\n",
    "df[\"is_train\"] = df[\"volgnr\"].isin(train_boeren) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_val\"] = df[\"volgnr\"].isin(val_boeren) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_test\"] = df[\"volgnr\"].isin(test_boeren) & (df[\"jaar\"] == 2024)\n",
    "\n",
    "# 7. Select top features (without exogenous variables)\n",
    "top_features = [\n",
    "    'eindsaldo_liquide_middelen', 'mutaties_vorderingen_en_schulden', 'overige_vorderingen', 'melkprijs_per_kg',\n",
    "    'crediteuren', 'melkprijs_per_kg_lag_6', 'leningen.1', 'mutatie_crediteuren',\n",
    "    'resultaat_vóór_bijzondere_resultaten', 'energiekosten', 'totale_kasstroom_lag_1',\n",
    "    'voorschot_melkgeld', 'melkprijs_per_kg_lag_1', 'maand', 'totaal_opbrengsten_lag_3',\n",
    "    'debiteuren', 'grasland', 'accountantskosten', 'koesaldo_per_kg_fosfaat',\n",
    "    'melkprijs_per_kg_lag_3', 'daadwerkelijke_aflossingen_in_het_jaar', 'ruwvoeraankopen.1',\n",
    "    'gewasbeschermingsmiddelen', 'overige_mutaties_operationele_activiteiten', 'krachtvoerkosten_lag_6',\n",
    "    'totale_kosten_excl_afschrijvingen', 'totaal_opbrengsten_lag_6', 'overige_banken',\n",
    "    'schoonmaakkosten_gebouwen', 'saldo_omzetbelasting', 'opfokkosten_en_weidegeld_per_100_kg_melk',\n",
    "    'melkkoeien_(€)', 'krachtvoerkosten', 'gebouwen', 'overige_bedrijfsopbrengsten',\n",
    "    'eiwitgehalte', 'financiële_baten_en_lasten', 'afschrijving_productierechten',\n",
    "    'totaal_opbrengsten_lag_1', 'resultaat_vóór_belastingen', 'totale_uitgaven', 'marge',\n",
    "    'aantal_melkkoeien_per_ha', 'voerkosten', 'boekjaar', 'mutatie_debiteuren', 'totaal_opbrengsten',\n",
    "    'afschrijving_auto(s)', 'opbrengst_nuka', 'personeelskosten_%_van_de_opbrengsten',\n",
    "    '%_insteek_van_de_melkkoeien', 'bijzondere_resultaten', 'kas',\n",
    "    \"eindsaldo_liquide_middelen_lag_1\", \"mutaties_vorderingen_en_schulden_lag_1\",\n",
    "    \"eindsaldo_liquide_middelen_lag_6\", \"mutaties_lag_6\", \"ratio_schulden_opbrengst\",\n",
    "    \"kasratio\", \"melkprijs_diff_6\"\n",
    "]\n",
    "NUM_FEATURES_TO_USE = 50\n",
    "feature_cols = [f for f in top_features if f in df.columns][:NUM_FEATURES_TO_USE]\n",
    "\n",
    "# 8. Sequence building\n",
    "sequence_length = 12\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, sequence_datums = [], [], [], [], [], [], []\n",
    "\n",
    "def build_sequences(boer_df, flag_col):\n",
    "    X_seq, y_seq, datums = [], [], []\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if not input_window[flag_col].all() and not target_row[flag_col]:\n",
    "            continue\n",
    "        X_seq.append(input_window[feature_cols].values)\n",
    "        y_seq.append(target_row[\"target\"])\n",
    "        datums.append(target_row[\"datum\"])\n",
    "    return X_seq, y_seq, datums\n",
    "\n",
    "for _, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    x_tr, y_tr, _ = build_sequences(boer_df, \"is_train\")\n",
    "    x_va, y_va, _ = build_sequences(boer_df, \"is_val\")\n",
    "    x_te, y_te, dts = build_sequences(boer_df, \"is_test\")\n",
    "    X_train.extend(x_tr)\n",
    "    y_train.extend(y_tr)\n",
    "    X_val.extend(x_va)\n",
    "    y_val.extend(y_va)\n",
    "    X_test.extend(x_te)\n",
    "    y_test.extend(y_te)\n",
    "    sequence_datums.extend(dts)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# 9. Scaling\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[2])).reshape(X_train.shape)\n",
    "X_val_scaled = feature_scaler.transform(X_val.reshape(-1, X_val.shape[2])).reshape(X_val.shape)\n",
    "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[2])).reshape(X_test.shape)\n",
    "\n",
    "# 10. Print shape check\n",
    "print(\"X_train:\", X_train_scaled.shape)\n",
    "print(\"X_val:\", X_val_scaled.shape)\n",
    "print(\"X_test:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8115d-ecbf-4ac4-b2e6-a838131f162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.losses import Huber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_size = 130\n",
    "num_layers = 1\n",
    "dropout = 0.49695170305447367\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0006011904275630357\n",
    "\n",
    "# Model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.GRU(hidden_size, return_sequences=(num_layers > 1), input_shape=X_train_scaled.shape[1:]))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "for _ in range(num_layers - 1):\n",
    "    model.add(layers.GRU(hidden_size, return_sequences=(_ < num_layers - 2)))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=Huber(delta=1.0))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model (no early stopping)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions (scaled)\n",
    "y_train_pred_scaled = model.predict(X_train_scaled)\n",
    "y_val_pred_scaled = model.predict(X_val_scaled)\n",
    "y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_train_pred = target_scaler.inverse_transform(y_train_pred_scaled)\n",
    "y_val_pred = target_scaler.inverse_transform(y_val_pred_scaled)\n",
    "y_test_pred = target_scaler.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "# Evaluation output\n",
    "print(\"\\nPost inverse_transform check:\")\n",
    "print(\"Unscaled predictions (test):\", y_test_pred[:5].flatten())\n",
    "print(\"Actual y_test:\", y_test[:5])\n",
    "\n",
    "print(\"\\nStandard deviation check:\")\n",
    "print(\"std(y_test):\", np.std(y_test))\n",
    "print(\"std(y_test_pred):\", np.std(y_test_pred))\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(true, pred, label):\n",
    "    rmse = mean_squared_error(true, pred, squared=False)\n",
    "    r2 = r2_score(true, pred)\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    print(f\"\\n{label} Results:\")\n",
    "    print(f\"RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    print(f\"MAE: €{mae:,.2f}\")\n",
    "    return rmse, r2, mae\n",
    "\n",
    "# Evaluate on all sets\n",
    "evaluate(y_train, y_train_pred, \"Train\")\n",
    "evaluate(y_val, y_val_pred, \"Validation\")\n",
    "evaluate(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Monthly average plot (test set)\n",
    "df_preds = pd.DataFrame({\n",
    "    \"date\": sequence_datums[-len(y_test):],\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_test_pred.flatten()\n",
    "})\n",
    "df_preds[\"month\"] = pd.to_datetime(df_preds[\"date\"]).dt.month\n",
    "monthly_avg = df_preds.groupby(\"month\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", marker=\"o\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted\", marker=\"o\", linestyle=\"--\")\n",
    "plt.title(\"GRU Forecast – 2024 (Test Farms)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f063181-e425-418a-b872-ccc92f87ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training dates for plotting\n",
    "train_sequence_datums = []\n",
    "for boer_id, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if input_window[\"is_train\"].all():\n",
    "            train_sequence_datums.append(target_row[\"datum\"])\n",
    "\n",
    "# Create combined DataFrame for actual and predicted values\n",
    "df_plot = pd.DataFrame({\n",
    "    \"datum\": pd.to_datetime(train_sequence_datums + sequence_datums),\n",
    "    \"y_true\": np.concatenate([y_train.flatten(), y_test.flatten()]),\n",
    "    \"y_pred\": np.concatenate([np.full_like(y_train.flatten(), np.nan), y_test_pred.flatten()])\n",
    "})\n",
    "\n",
    "# Set datetime index for resampling\n",
    "df_plot = df_plot.sort_values(\"datum\").set_index(\"datum\")\n",
    "\n",
    "# Compute monthly averages\n",
    "monthly_avg = df_plot.resample(\"M\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "# Plot monthly average actual vs predicted cash flow\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", color=\"blue\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted (2024)\", color=\"orangered\", linestyle=\"--\")\n",
    "plt.title(\"GRU Forecast Without Exogenous Variables – Monthly Average Cash Flow (2020–2024)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
