{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6e70d-95da-499f-a18a-febdefbce20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "from tensorflow.keras.losses import Huber\n",
    "# 1. Load and sort data\n",
    "df = pd.read_csv(\"data_final.csv\", parse_dates=[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "\n",
    "# 2. Time-based features\n",
    "df[\"jaar\"] = df[\"datum\"].dt.year\n",
    "df[\"maand\"] = df[\"datum\"].dt.month\n",
    "\n",
    "# 3. Define target: next month's cash flow\n",
    "df[\"target\"] = df.groupby(\"volgnr\")[\"totale_kasstroom\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# Apply winsorization (same logic as XGBoost model)\n",
    "df[\"target\"] = pd.Series(winsorize(df[\"target\"], limits=[0.01, 0.01]), index=df.index)\n",
    "\n",
    "# 4. Add lagged and derived features\n",
    "df[\"eindsaldo_liquide_middelen_lag_1\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(1)\n",
    "df[\"mutaties_vorderingen_en_schulden_lag_1\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(1)\n",
    "df[\"eindsaldo_liquide_middelen_lag_6\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(6)\n",
    "df[\"mutaties_lag_6\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(6)\n",
    "df[\"ratio_schulden_opbrengst\"] = df[\"mutaties_vorderingen_en_schulden\"] / (df[\"totaal_opbrengsten_lag_1\"] + 1e-6)\n",
    "df[\"kasratio\"] = df[\"kas\"] / (df[\"totale_kasstroom_lag_1\"] + 1e-6)\n",
    "df[\"melkprijs_diff_6\"] = df[\"melkprijs_per_kg\"] - df[\"melkprijs_per_kg\"].shift(6)\n",
    "\n",
    "# 4b. Fill NaNs in lagged/diff columns per farm\n",
    "lagged_cols = [col for col in df.columns if any(p in col for p in [\"_lag_\", \"_diff_\", \"ratio_\", \"kasratio\"])]\n",
    "df[lagged_cols] = df.groupby(\"volgnr\")[lagged_cols].transform(lambda x: x.bfill().ffill())\n",
    "\n",
    "# 5. Train/validation/test split by farm\n",
    "farms = df[\"volgnr\"].unique()\n",
    "trainval_farms, test_farms = train_test_split(farms, test_size=0.2, random_state=42)\n",
    "train_farms, val_farms = train_test_split(trainval_farms, test_size=0.2, random_state=42)\n",
    "\n",
    "df[\"is_train\"] = df[\"volgnr\"].isin(train_farms) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_val\"] = df[\"volgnr\"].isin(val_farms) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_test\"] = df[\"volgnr\"].isin(test_farms) & (df[\"jaar\"] == 2024)\n",
    "\n",
    "# 6. Top 50 most important features according to SHAP values from XGBoost model\n",
    "NUM_FEATURES_TO_USE = 50\n",
    "all_features = [f for f in [\n",
    "    'eindsaldo_liquide_middelen', 'mutaties_vorderingen_en_schulden', 'overige_vorderingen', 'melkprijs_per_kg',\n",
    "    'crediteuren', 'melkprijs_per_kg_lag_6', 'leningen.1', 'mutatie_crediteuren',\n",
    "    'resultaat_vóór_bijzondere_resultaten', 'energiekosten', 'neerslag_(mm)', 'totale_kasstroom_lag_1',\n",
    "    'voorschot_melkgeld', 'melkprijs_per_kg_lag_1', 'maand', 'totaal_opbrengsten_lag_3',\n",
    "    'volgnr', 'debiteuren', 'grasland', 'accountantskosten',\n",
    "    'koesaldo_per_kg_fosfaat', 'melkprijs_per_kg_lag_3', 'daadwerkelijke_aflossingen_in_het_jaar',\n",
    "    'ruwvoeraankopen.1', 'gewasbeschermingsmiddelen', 'overige_mutaties_operationele_activiteiten',\n",
    "    'krachtvoerkosten_lag_6', 'totale_kosten_excl_afschrijvingen', 'totaal_opbrengsten_lag_6',\n",
    "    'overige_banken', 'schoonmaakkosten_gebouwen', 'saldo_omzetbelasting',\n",
    "    'opfokkosten_en_weidegeld_per_100_kg_melk', 'melkkoeien_(€)', 'krachtvoerkosten', 'gebouwen',\n",
    "    'overige_bedrijfsopbrengsten', 'eiwitgehalte', 'financiële_baten_en_lasten',\n",
    "    'afschrijving_productierechten', 'totaal_opbrengsten_lag_1', 'resultaat_vóór_belastingen',\n",
    "    'totale_uitgaven', 'marge', 'aantal_melkkoeien_per_ha', 'voerkosten',\n",
    "    'gemiddelde_temperatuur', 'boekjaar', 'mutatie_debiteuren', 'totaal_opbrengsten',\n",
    "    'afschrijving_auto(s)', 'opbrengst_nuka', 'personeelskosten_%_van_de_opbrengsten',\n",
    "    '%_insteek_van_de_melkkoeien', 'bijzondere_resultaten', 'kas', 'gemiddelde_temperatuur_lag_6',\n",
    "    'investering_grond_en_gebouwen', 'ureumgehalte', 'waarvan_loonwerk_per_ha',\n",
    "    'onttrekkingen,_prive_xb9010', 'percentage_jongvee', 'ruwvoerkosten.1',\n",
    "    'advieskosten', 'pensioenlasten', 'bedrijfskosten', 'gas,_water_en_electra',\n",
    "    'overige_kosten_inventaris_en_machines', \"eindsaldo_liquide_middelen_lag_1\",\n",
    "    \"mutaties_vorderingen_en_schulden_lag_1\", \"eindsaldo_liquide_middelen_lag_6\",\n",
    "    \"mutaties_lag_6\", \"ratio_schulden_opbrengst\", \"kasratio\", \"melkprijs_diff_6\"\n",
    "] if f in df.columns]\n",
    "features = all_features[:NUM_FEATURES_TO_USE]\n",
    "\n",
    "# 7. Build sequences\n",
    "sequence_length = 12\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, sequence_datums = [], [], [], [], [], [], []\n",
    "\n",
    "def build_sequences(farm_df, flag_col):\n",
    "    X_seq, y_seq, datums = [], [], []\n",
    "    for i in range(len(farm_df) - sequence_length):\n",
    "        input_window = farm_df.iloc[i:i + sequence_length]\n",
    "        target_row = farm_df.iloc[i + sequence_length]\n",
    "        if not input_window[flag_col].all() and not target_row[flag_col]:\n",
    "            continue\n",
    "        X_seq.append(input_window[features].values)\n",
    "        y_seq.append(target_row[\"target\"])\n",
    "        datums.append(target_row[\"datum\"])\n",
    "    return X_seq, y_seq, datums\n",
    "\n",
    "for _, farm_df in df.groupby(\"volgnr\"):\n",
    "    farm_df = farm_df.sort_values(\"datum\")\n",
    "    x_tr, y_tr, _ = build_sequences(farm_df, \"is_train\")\n",
    "    x_va, y_va, _ = build_sequences(farm_df, \"is_val\")\n",
    "    x_te, y_te, dts = build_sequences(farm_df, \"is_test\")\n",
    "    X_train.extend(x_tr)\n",
    "    y_train.extend(y_tr)\n",
    "    X_val.extend(x_va)\n",
    "    y_val.extend(y_va)\n",
    "    X_test.extend(x_te)\n",
    "    y_test.extend(y_te)\n",
    "    sequence_datums.extend(dts)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 8. Normalize features and targets\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[2])).reshape(X_train.shape)\n",
    "X_val_scaled = feature_scaler.transform(X_val.reshape(-1, X_val.shape[2])).reshape(X_val.shape)\n",
    "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[2])).reshape(X_test.shape)\n",
    "\n",
    "# 9. Final shape check\n",
    "print(\"X_train:\", X_train_scaled.shape)\n",
    "print(\"X_val:  \", X_val_scaled.shape)\n",
    "print(\"X_test: \", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83388b-924e-4c81-b20e-269f6b2f0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "# --------------------------\n",
    "# Model Hyperparameters\n",
    "# --------------------------\n",
    "hidden_size = 236\n",
    "num_layers = 3\n",
    "dropout = 0.10\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0006\n",
    "\n",
    "# --------------------------\n",
    "# Model Architecture\n",
    "# --------------------------\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(hidden_size, return_sequences=True, input_shape=X_train_scaled.shape[1:]))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.LSTM(hidden_size, return_sequences=True))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.LSTM(hidden_size))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=Huber(delta=1.0))\n",
    "model.summary()\n",
    "\n",
    "# --------------------------\n",
    "# Model Training (without early stopping)\n",
    "# --------------------------\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Predictions (scaled)\n",
    "# --------------------------\n",
    "y_train_pred_scaled = model.predict(X_train_scaled)\n",
    "y_val_pred_scaled = model.predict(X_val_scaled)\n",
    "y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform predictions to original cash flow (€)\n",
    "y_train_pred = target_scaler.inverse_transform(y_train_pred_scaled)\n",
    "y_val_pred = target_scaler.inverse_transform(y_val_pred_scaled)\n",
    "y_test_pred = target_scaler.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluation Function\n",
    "# --------------------------\n",
    "def evaluate(y_true, y_pred, label):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    print(f\"\\n{label} Set Performance:\")\n",
    "    print(f\"RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"MAE:  €{mae:,.2f}\")\n",
    "    print(f\"R²:    {r2:.3f}\")\n",
    "    print(f\"MAPE:  {mape:.2f}%\")\n",
    "    return rmse, r2, mae, mape\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate(y_train, y_train_pred, \"Train\")\n",
    "evaluate(y_val, y_val_pred, \"Validation\")\n",
    "evaluate(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# --------------------------\n",
    "# Scatter Plot: Predicted vs Actual (Test Set)\n",
    "# --------------------------\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.xlabel(\"Actual Cash Flow (€)\")\n",
    "plt.ylabel(\"Predicted Cash Flow (€)\")\n",
    "plt.title(\"LSTM: Predicted vs Actual (Test Set)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Monthly Average Plot (2024)\n",
    "# --------------------------\n",
    "df_preds = pd.DataFrame({\n",
    "    \"date\": sequence_datums[-len(y_test):],\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_test_pred.flatten()\n",
    "})\n",
    "df_preds[\"month\"] = pd.to_datetime(df_preds[\"date\"]).dt.month\n",
    "monthly_avg = df_preds.groupby(\"month\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", marker=\"o\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted\", marker=\"o\", linestyle=\"--\")\n",
    "plt.title(\"LSTM Forecast – Monthly Average Cash Flow (2024)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be01306-7544-4541-9bde-764a8b3fab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Collect timestamps for all training sequences (targets)\n",
    "train_sequence_dates = []\n",
    "for farm_id, farm_df in df.groupby(\"volgnr\"):\n",
    "    farm_df = farm_df.sort_values(\"datum\")\n",
    "    for i in range(len(farm_df) - sequence_length):\n",
    "        input_window = farm_df.iloc[i:i + sequence_length]\n",
    "        target_row = farm_df.iloc[i + sequence_length]\n",
    "        if input_window[\"is_train\"].all():\n",
    "            train_sequence_dates.append(target_row[\"datum\"])\n",
    "\n",
    "# Step 2: Construct a combined DataFrame for plotting\n",
    "# - Training predictions are set to NaN to visually distinguish forecast period\n",
    "df_plot = pd.DataFrame({\n",
    "    \"date\": pd.to_datetime(train_sequence_dates + sequence_datums),\n",
    "    \"y_true\": np.concatenate([y_train.flatten(), y_test.flatten()]),\n",
    "    \"y_pred\": np.concatenate([\n",
    "        np.full_like(y_train.flatten(), np.nan),  # no predictions in training period\n",
    "        y_test_pred.flatten()\n",
    "    ])\n",
    "})\n",
    "\n",
    "# Step 3: Set time index and aggregate by month\n",
    "df_plot = df_plot.sort_values(\"date\").set_index(\"date\")\n",
    "monthly_avg = df_plot.resample(\"M\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "# Step 4: Plotting monthly averages (2020–2024)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", color=\"blue\", linewidth=2)\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Forecast (2024)\", color=\"orangered\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Optional: Mark start of the forecast period\n",
    "plt.axvline(pd.to_datetime(\"2024-01-01\"), color=\"gray\", linestyle=\":\", label=\"Forecast Start\")\n",
    "\n",
    "# Final plot annotations\n",
    "plt.title(\"LSTM Forecast with Exogenous Variables – Monthly Average Cash Flow (2020–2024)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a190d-555d-4329-8df7-d87f07c5f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "def permutation_feature_importance(model, X, y_true, scaler, baseline_preds, feature_names, n_repeats=5):\n",
    "    \"\"\"\n",
    "    Computes permutation-based feature importance for a sequence model (e.g., LSTM).\n",
    "    \"\"\"\n",
    "    baseline_rmse = mean_squared_error(y_true, baseline_preds, squared=False)\n",
    "    importances = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(X.shape[2]), desc=\"Calculating feature importance\"):\n",
    "        rmse_diffs = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = copy.deepcopy(X)\n",
    "            for t in range(X.shape[1]):\n",
    "                np.random.shuffle(X_permuted[:, t, i])\n",
    "            y_pred_scaled = model.predict(X_permuted, verbose=0)\n",
    "            y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "            rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "            rmse_diffs.append(rmse - baseline_rmse)\n",
    "        importances.append(np.mean(rmse_diffs))\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Feature\": feature_names,\n",
    "        \"Importance (RMSE increase)\": importances\n",
    "    }).sort_values(by=\"Importance (RMSE increase)\", ascending=False)\n",
    "# Baseline predictions (unscaled)\n",
    "baseline_preds = y_test_pred\n",
    "\n",
    "# Compute importances\n",
    "importance_df = permutation_feature_importance(\n",
    "    model=model,\n",
    "    X=X_test_scaled,\n",
    "    y_true=y_test,\n",
    "    scaler=target_scaler,\n",
    "    baseline_preds=baseline_preds,\n",
    "    feature_names=feature_cols,\n",
    "    n_repeats=3\n",
    ")\n",
    "\n",
    "# Plot top 10\n",
    "top10 = importance_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(top10[\"Feature\"][::-1], top10[\"Importance (RMSE increase)\"][::-1])\n",
    "plt.xlabel(\"Increase in RMSE when permuted\")\n",
    "plt.title(\"Top 10 Feature Importances (LSTM – Permutation)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded91aa-3b46-4b57-966b-4693c43b27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary: Dutch to English feature name mapping\n",
    "translation_dict = {\n",
    "    \"eindsaldo_liquide_middelen\": \"ending_cash_balance\",\n",
    "    \"totaal_opbrengsten\": \"total_revenue\",\n",
    "    \"debiteuren\": \"accounts_receivable\",\n",
    "    \"melkprijs_per_kg_lag_1\": \"milk_price_lag_1\",\n",
    "    \"totaal_opbrengsten_lag_3\": \"total_revenue_lag_3\",\n",
    "    \"totaal_opbrengsten_lag_6\": \"total_revenue_lag_6\",\n",
    "    \"schoonmaakkosten_gebouwen\": \"building_cleaning_costs\",\n",
    "    \"overige_vorderingen\": \"other_receivables\",\n",
    "    \"overige_banken\": \"other_banks\",\n",
    "    \"koesaldo_per_kg_fosfaat\": \"cow_balance_per_kg_phosphate\",\n",
    "    \"aantal_melkkoeien_per_ha\": \"dairy_cows_per_hectare\",\n",
    "    \"overige_mutaties_operationele_activiteiten\": \"other_operational_changes\",\n",
    "    \"opfokkosten_en_weidegeld_per_100_kg_melk\": \"raising_and_grazing_costs_per_100kg_milk\",\n",
    "    \"overige_bedrijfsopbrengsten\": \"other_operating_income\",\n",
    "    \"totaal_opbrengsten_lag_1\": \"total_revenue_lag_1\"\n",
    "}\n",
    "\n",
    "# Apply translation if feature is in dictionary\n",
    "importance_df[\"Feature\"] = importance_df[\"Feature\"].map(lambda x: translation_dict.get(x, x))\n",
    "\n",
    "# Plot the top 10 most important features\n",
    "top10 = importance_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(top10[\"Feature\"][::-1], top10[\"Importance (RMSE increase)\"][::-1])\n",
    "plt.xlabel(\"Increase in RMSE when permuted\")\n",
    "plt.title(\"Top 10 Feature Importances (LSTM – Permutation)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0566766-603d-417f-8919-48197bc4908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 1. Load and prepare the dataset\n",
    "df = pd.read_csv(\"data_final.csv\", parse_dates=[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "df[\"year\"] = df[\"datum\"].dt.year\n",
    "df[\"month\"] = df[\"datum\"].dt.month\n",
    "\n",
    "# 2. Construct the target variable (next month's cash flow)\n",
    "df[\"target\"] = df.groupby(\"volgnr\")[\"totale_kasstroom\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# Apply winsorization (same logic as XGBoost model)\n",
    "df[\"target\"] = pd.Series(winsorize(df[\"target\"], limits=[0.01, 0.01]), index=df.index)\n",
    "\n",
    "# 3. Create engineered features (lags, ratios, etc.)\n",
    "df[\"eindsaldo_liquide_middelen_lag_1\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(1)\n",
    "df[\"mutaties_vorderingen_en_schulden_lag_1\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(1)\n",
    "df[\"eindsaldo_liquide_middelen_lag_6\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(6)\n",
    "df[\"mutaties_lag_6\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(6)\n",
    "df[\"ratio_schulden_opbrengst\"] = df[\"mutaties_vorderingen_en_schulden\"] / (df[\"totaal_opbrengsten_lag_1\"] + 1e-6)\n",
    "df[\"kasratio\"] = df[\"kas\"] / (df[\"totale_kasstroom_lag_1\"] + 1e-6)\n",
    "df[\"melkprijs_diff_6\"] = df[\"melkprijs_per_kg\"] - df[\"melkprijs_per_kg\"].shift(6)\n",
    "\n",
    "# 4. Fill missing values for lagged and derived features\n",
    "lagged_cols = [col for col in df.columns if any(pat in col for pat in [\"_lag_\", \"_diff_\", \"ratio_\", \"kasratio\"])]\n",
    "df[lagged_cols] = df.groupby(\"volgnr\")[lagged_cols].transform(lambda x: x.bfill().ffill())\n",
    "\n",
    "# 5. Split farms into train, validation, and test sets\n",
    "boeren = df[\"volgnr\"].unique()\n",
    "trainval_boeren, test_boeren = train_test_split(boeren, test_size=0.2, random_state=42)\n",
    "train_boeren, val_boeren = train_test_split(trainval_boeren, test_size=0.2, random_state=42)\n",
    "\n",
    "df[\"is_train\"] = df[\"volgnr\"].isin(train_boeren) & (df[\"year\"] < 2024)\n",
    "df[\"is_val\"] = df[\"volgnr\"].isin(val_boeren) & (df[\"year\"] < 2024)\n",
    "df[\"is_test\"] = df[\"volgnr\"].isin(test_boeren) & (df[\"year\"] == 2024)\n",
    "\n",
    "# 6. Select top features (replace with your SHAP-ranked list)\n",
    "top_features = [...]  # <-- your SHAP-based top 50 feature list\n",
    "feature_cols = [col for col in top_features if col in df.columns][:50]\n",
    "\n",
    "# 7. Build sequences\n",
    "sequence_length = 12\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "sequence_datums, sequence_volgnrs = [], []\n",
    "\n",
    "def build_sequences(boer_df, flag_col):\n",
    "    X_seq, y_seq, datums, volgnrs = [], [], [], []\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if not input_window[flag_col].all() and not target_row[flag_col]:\n",
    "            continue\n",
    "        X_seq.append(input_window[feature_cols].values)\n",
    "        y_seq.append(target_row[\"target\"])\n",
    "        datums.append(target_row[\"datum\"])\n",
    "        volgnrs.append(target_row[\"volgnr\"])\n",
    "    return X_seq, y_seq, datums, volgnrs\n",
    "\n",
    "for _, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    x_tr, y_tr, _, _ = build_sequences(boer_df, \"is_train\")\n",
    "    x_va, y_va, _, _ = build_sequences(boer_df, \"is_val\")\n",
    "    x_te, y_te, dts, vols = build_sequences(boer_df, \"is_test\")\n",
    "    X_train.extend(x_tr)\n",
    "    y_train.extend(y_tr)\n",
    "    X_val.extend(x_va)\n",
    "    y_val.extend(y_val)\n",
    "    X_test.extend(x_te)\n",
    "    y_test.extend(y_te)\n",
    "    sequence_datums.extend(dts)\n",
    "    sequence_volgnrs.extend(vols)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# 8. Scaling\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[2])).reshape(X_train.shape)\n",
    "X_val_scaled = feature_scaler.transform(X_val.reshape(-1, X_val.shape[2])).reshape(X_val.shape)\n",
    "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[2])).reshape(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ad765-c494-489b-a5d9-e4c5f39f83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect training dates again\n",
    "train_sequence_datums = []\n",
    "train_sequence_volgnrs = []\n",
    "for boer_id, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if input_window[\"is_train\"].all():\n",
    "            train_sequence_datums.append(target_row[\"datum\"])\n",
    "            train_sequence_volgnrs.append(target_row[\"volgnr\"])\n",
    "\n",
    "# Build full DataFrame\n",
    "df_plot = pd.DataFrame({\n",
    "    \"datum\": pd.to_datetime(train_sequence_datums + sequence_datums),\n",
    "    \"volgnr\": np.concatenate([train_sequence_volgnrs, sequence_volgnrs]),\n",
    "    \"y_true\": np.concatenate([y_train.flatten(), y_test.flatten()]),\n",
    "    \"y_pred\": np.concatenate([np.full_like(y_train.flatten(), np.nan), y_test_pred.flatten()])\n",
    "})\n",
    "\n",
    "# Merge clusters\n",
    "df_clusters = df[[\"datum\", \"volgnr\", \"bedrijf_cluster\"]].drop_duplicates()\n",
    "df_plot = df_plot.merge(df_clusters, on=[\"datum\", \"volgnr\"], how=\"left\")\n",
    "\n",
    "# Set date index\n",
    "df_plot = df_plot.sort_values(\"datum\").set_index(\"datum\")\n",
    "\n",
    "# Create subplots\n",
    "unique_clusters = sorted(df_plot[\"bedrijf_cluster\"].dropna().unique())\n",
    "n_clusters = len(unique_clusters)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_clusters, figsize=(6 * n_clusters, 5), sharey=True)\n",
    "\n",
    "for i, cluster in enumerate(unique_clusters):\n",
    "    ax = axes[i] if n_clusters > 1 else axes\n",
    "    df_cluster = df_plot[df_plot[\"bedrijf_cluster\"] == cluster]\n",
    "\n",
    "    # Group by month\n",
    "    monthly_avg = df_cluster.resample(\"M\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "    ax.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual (2020–2024)\", color=\"blue\")\n",
    "    ax.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted (2024)\", color=\"orangered\", linestyle=\"--\")\n",
    "    ax.set_title(f\"Cluster {int(cluster)}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Average Cash Flow (€)\")\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='x', rotation=45) \n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle(\"LSTM Forecast – Monthly Average Cash Flow per Cluster (2020–2024)\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51923653-c384-47e6-9eed-23891df6ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 1. Load and sort data\n",
    "df = pd.read_csv(\"data_final.csv\", parse_dates=[\"datum\"])\n",
    "df = df.sort_values([\"volgnr\", \"datum\"]).reset_index(drop=True)\n",
    "\n",
    "# 2. Create time features\n",
    "df[\"jaar\"] = df[\"datum\"].dt.year\n",
    "df[\"maand\"] = df[\"datum\"].dt.month\n",
    "\n",
    "# 3. Create target (next month cash flow)\n",
    "df[\"target\"] = df.groupby(\"volgnr\")[\"totale_kasstroom\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df[\"target\"] = pd.Series(winsorize(df[\"target\"], limits=[0.01, 0.01]), index=df.index)\n",
    "\n",
    "# 4. Add engineered features\n",
    "df[\"eindsaldo_liquide_middelen_lag_1\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(1)\n",
    "df[\"mutaties_vorderingen_en_schulden_lag_1\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(1)\n",
    "df[\"eindsaldo_liquide_middelen_lag_6\"] = df.groupby(\"volgnr\")[\"eindsaldo_liquide_middelen\"].shift(6)\n",
    "df[\"mutaties_lag_6\"] = df.groupby(\"volgnr\")[\"mutaties_vorderingen_en_schulden\"].shift(6)\n",
    "df[\"ratio_schulden_opbrengst\"] = df[\"mutaties_vorderingen_en_schulden\"] / (df[\"totaal_opbrengsten_lag_1\"] + 1e-6)\n",
    "df[\"kasratio\"] = df[\"kas\"] / (df[\"totale_kasstroom_lag_1\"] + 1e-6)\n",
    "df[\"melkprijs_diff_6\"] = df[\"melkprijs_per_kg\"] - df[\"melkprijs_per_kg\"].shift(6)\n",
    "\n",
    "# 5. Fill engineered features within each farm\n",
    "lagged_cols = [col for col in df.columns if any(pat in col for pat in [\"_lag_\", \"_diff_\", \"ratio_\", \"kasratio\"])]\n",
    "df[lagged_cols] = df.groupby(\"volgnr\")[lagged_cols].transform(lambda x: x.bfill().ffill())\n",
    "\n",
    "# 6. Train/val/test split\n",
    "boeren = df[\"volgnr\"].unique()\n",
    "trainval_boeren, test_boeren = train_test_split(boeren, test_size=0.2, random_state=42)\n",
    "train_boeren, val_boeren = train_test_split(trainval_boeren, test_size=0.2, random_state=42)\n",
    "\n",
    "df[\"is_train\"] = df[\"volgnr\"].isin(train_boeren) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_val\"] = df[\"volgnr\"].isin(val_boeren) & (df[\"jaar\"] < 2024)\n",
    "df[\"is_test\"] = df[\"volgnr\"].isin(test_boeren) & (df[\"jaar\"] == 2024)\n",
    "\n",
    "# 7. Select top features (without exogenous variables)\n",
    "top_features = [\n",
    "    'eindsaldo_liquide_middelen', 'mutaties_vorderingen_en_schulden', 'overige_vorderingen', 'melkprijs_per_kg',\n",
    "    'crediteuren', 'melkprijs_per_kg_lag_6', 'leningen.1', 'mutatie_crediteuren',\n",
    "    'resultaat_vóór_bijzondere_resultaten', 'energiekosten', 'totale_kasstroom_lag_1',\n",
    "    'voorschot_melkgeld', 'melkprijs_per_kg_lag_1', 'maand', 'totaal_opbrengsten_lag_3',\n",
    "    'debiteuren', 'grasland', 'accountantskosten', 'koesaldo_per_kg_fosfaat',\n",
    "    'melkprijs_per_kg_lag_3', 'daadwerkelijke_aflossingen_in_het_jaar', 'ruwvoeraankopen.1',\n",
    "    'gewasbeschermingsmiddelen', 'overige_mutaties_operationele_activiteiten', 'krachtvoerkosten_lag_6',\n",
    "    'totale_kosten_excl_afschrijvingen', 'totaal_opbrengsten_lag_6', 'overige_banken',\n",
    "    'schoonmaakkosten_gebouwen', 'saldo_omzetbelasting', 'opfokkosten_en_weidegeld_per_100_kg_melk',\n",
    "    'melkkoeien_(€)', 'krachtvoerkosten', 'gebouwen', 'overige_bedrijfsopbrengsten',\n",
    "    'eiwitgehalte', 'financiële_baten_en_lasten', 'afschrijving_productierechten',\n",
    "    'totaal_opbrengsten_lag_1', 'resultaat_vóór_belastingen', 'totale_uitgaven', 'marge',\n",
    "    'aantal_melkkoeien_per_ha', 'voerkosten', 'boekjaar', 'mutatie_debiteuren', 'totaal_opbrengsten',\n",
    "    'afschrijving_auto(s)', 'opbrengst_nuka', 'personeelskosten_%_van_de_opbrengsten',\n",
    "    '%_insteek_van_de_melkkoeien', 'bijzondere_resultaten', 'kas',\n",
    "    \"eindsaldo_liquide_middelen_lag_1\", \"mutaties_vorderingen_en_schulden_lag_1\",\n",
    "    \"eindsaldo_liquide_middelen_lag_6\", \"mutaties_lag_6\", \"ratio_schulden_opbrengst\",\n",
    "    \"kasratio\", \"melkprijs_diff_6\"\n",
    "]\n",
    "NUM_FEATURES_TO_USE = 50\n",
    "feature_cols = [f for f in top_features if f in df.columns][:NUM_FEATURES_TO_USE]\n",
    "\n",
    "# 8. Sequence building\n",
    "sequence_length = 12\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, sequence_datums = [], [], [], [], [], [], []\n",
    "\n",
    "def build_sequences(boer_df, flag_col):\n",
    "    X_seq, y_seq, datums = [], [], []\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if not input_window[flag_col].all() and not target_row[flag_col]:\n",
    "            continue\n",
    "        X_seq.append(input_window[feature_cols].values)\n",
    "        y_seq.append(target_row[\"target\"])\n",
    "        datums.append(target_row[\"datum\"])\n",
    "    return X_seq, y_seq, datums\n",
    "\n",
    "for _, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    x_tr, y_tr, _ = build_sequences(boer_df, \"is_train\")\n",
    "    x_va, y_va, _ = build_sequences(boer_df, \"is_val\")\n",
    "    x_te, y_te, dts = build_sequences(boer_df, \"is_test\")\n",
    "    X_train.extend(x_tr)\n",
    "    y_train.extend(y_tr)\n",
    "    X_val.extend(x_va)\n",
    "    y_val.extend(y_va)\n",
    "    X_test.extend(x_te)\n",
    "    y_test.extend(y_te)\n",
    "    sequence_datums.extend(dts)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# 9. Scaling\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[2])).reshape(X_train.shape)\n",
    "X_val_scaled = feature_scaler.transform(X_val.reshape(-1, X_val.shape[2])).reshape(X_val.shape)\n",
    "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[2])).reshape(X_test.shape)\n",
    "\n",
    "# 10. Check shapes\n",
    "print(\"X_train:\", X_train_scaled.shape)\n",
    "print(\"X_val:\", X_val_scaled.shape)\n",
    "print(\"X_test:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260bf27-ab41-4f28-a076-dcd8d37bff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "# --------------------------\n",
    "# Model Hyperparameters\n",
    "# --------------------------\n",
    "hidden_size = 236\n",
    "num_layers = 3\n",
    "dropout = 0.10\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0006\n",
    "\n",
    "# --------------------------\n",
    "# Model Architecture\n",
    "# --------------------------\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(hidden_size, return_sequences=True, input_shape=X_train_scaled.shape[1:]))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.LSTM(hidden_size, return_sequences=True))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.LSTM(hidden_size))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=Huber(delta=1.0))\n",
    "model.summary()\n",
    "\n",
    "# --------------------------\n",
    "# Model Training (without early stopping)\n",
    "# --------------------------\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Predictions (scaled)\n",
    "# --------------------------\n",
    "y_train_pred_scaled = model.predict(X_train_scaled)\n",
    "y_val_pred_scaled = model.predict(X_val_scaled)\n",
    "y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform predictions to original cash flow (€)\n",
    "y_train_pred = target_scaler.inverse_transform(y_train_pred_scaled)\n",
    "y_val_pred = target_scaler.inverse_transform(y_val_pred_scaled)\n",
    "y_test_pred = target_scaler.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluation Function\n",
    "# --------------------------\n",
    "def evaluate(y_true, y_pred, label):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    print(f\"\\n{label} Set Performance:\")\n",
    "    print(f\"RMSE: €{rmse:,.2f}\")\n",
    "    print(f\"MAE:  €{mae:,.2f}\")\n",
    "    print(f\"R²:    {r2:.3f}\")\n",
    "    print(f\"MAPE:  {mape:.2f}%\")\n",
    "    return rmse, r2, mae, mape\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate(y_train, y_train_pred, \"Train\")\n",
    "evaluate(y_val, y_val_pred, \"Validation\")\n",
    "evaluate(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# --------------------------\n",
    "# Scatter Plot: Predicted vs Actual (Test Set)\n",
    "# --------------------------\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.xlabel(\"Actual Cash Flow (€)\")\n",
    "plt.ylabel(\"Predicted Cash Flow (€)\")\n",
    "plt.title(\"LSTM: Predicted vs Actual (Test Set)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Monthly Average Plot (2024)\n",
    "# --------------------------\n",
    "df_preds = pd.DataFrame({\n",
    "    \"date\": sequence_datums[-len(y_test):],\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_test_pred.flatten()\n",
    "})\n",
    "df_preds[\"month\"] = pd.to_datetime(df_preds[\"date\"]).dt.month\n",
    "monthly_avg = df_preds.groupby(\"month\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", marker=\"o\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted\", marker=\"o\", linestyle=\"--\")\n",
    "plt.title(\"LSTM Forecast – Monthly Average Cash Flow (2024)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3ba2d-af4f-4296-be76-dfee23340544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training dates (if not already available)\n",
    "train_sequence_datums = []\n",
    "for boer_id, boer_df in df.groupby(\"volgnr\"):\n",
    "    boer_df = boer_df.sort_values(\"datum\")\n",
    "    for i in range(len(boer_df) - sequence_length):\n",
    "        input_window = boer_df.iloc[i:i + sequence_length]\n",
    "        target_row = boer_df.iloc[i + sequence_length]\n",
    "        if input_window[\"is_train\"].all():\n",
    "            train_sequence_datums.append(target_row[\"datum\"])\n",
    "\n",
    "# Rebuild DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    \"datum\": pd.to_datetime(train_sequence_datums + sequence_datums),\n",
    "    \"y_true\": np.concatenate([y_train.flatten(), y_test.flatten()]),\n",
    "    \"y_pred\": np.concatenate([np.full_like(y_train.flatten(), np.nan), y_test_pred.flatten()])\n",
    "})\n",
    "\n",
    "# Set date as index\n",
    "df_plot = df_plot.sort_values(\"datum\").set_index(\"datum\")\n",
    "\n",
    "# Aggregate by month\n",
    "monthly_avg = df_plot.resample(\"M\")[[\"y_true\", \"y_pred\"]].mean()\n",
    "\n",
    "# Plot: actual vs predicted cash flow (monthly average)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_true\"], label=\"Actual\", color=\"blue\")\n",
    "plt.plot(monthly_avg.index, monthly_avg[\"y_pred\"], label=\"Predicted (2024)\", color=\"orangered\", linestyle=\"--\")\n",
    "plt.title(\"LSTM Forecast Without Exogenous Variables – Monthly Average Cash Flow (2020–2024)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Cash Flow (€)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
